# SDXL LoRA Training for PBR Map Generation

model:
  pretrained_model: "stabilityai/stable-diffusion-xl-base-1.0"

lora:
  rank: 64          # LoRA rank (higher = more capacity, more VRAM)
  alpha: 64         # LoRA alpha (usually same as rank)
  dropout: 0.0      # LoRA dropout

training:
  data_dir: "./data"
  target_map: "normal"  # normal, roughness, or metallic
  resolution: 1024      # SDXL native resolution
  batch_size: 1         # Small batch for VRAM
  epochs: 50
  learning_rate: 1.0e-4
  weight_decay: 0.01
  warmup_steps: 100
  max_grad_norm: 1.0
  gradient_checkpointing: true
  mixed_precision: true  # fp16
  validation_epochs: 10

checkpointing:
  output_dir: "./output"
  save_epochs: 10

logging:
  use_wandb: true
  project_name: "pbr-sdxl-lora"

# Memory optimization for different GPUs:
# RTX 4090 (24GB): batch_size=1, resolution=1024, rank=64
# RTX 3090 (24GB): batch_size=1, resolution=1024, rank=32
# A100 (40GB): batch_size=2, resolution=1024, rank=128
# A100 (80GB): batch_size=4, resolution=1024, rank=128
